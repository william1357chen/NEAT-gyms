{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with the NeuroEvolution of Augmenting Topologies (NEAT) Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objective\n",
    "In this Jupyter Notebook, we will work on solving simple simulators with a Reinforcement Learning agent trained with the NEAT Algorithm. \n",
    "\n",
    "#### Problem\n",
    "Reinforcement learning is studied in multiple disciplines, as well as evolutionary algorithms. I'd like to research and learn interesting reinforcement learning techniques such as NEAT that solves Reinforcement learning tasks like AIs in video games, robots learning how to walk, etc.\n",
    "\n",
    "#### What is NEAT\n",
    "See the presentation on NEAT at https://docs.google.com/presentation/d/1H4W0TBSQHH-FQ18fmvH-Qv1MRaqOpOf0MI1bV-UftOM/edit#slide=id.g1096e8bacce_0_157\n",
    "\n",
    "Read the paper by the professor that discovered NEAT http://nn.cs.utexas.edu/downloads/papers/stanley.cec02.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements\n",
    "* The `neat-python` library installed with `pip install neat-python`\n",
    "* The OpenAI Gym library installed with `pip install gym`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to Formulate a problem for NEAT (or RL tasks)\n",
    "* Define the inputs (observations) and outputs (action)\n",
    "* Define the fitness function\n",
    "* Define the hyperparameters in config file (ie. population size, bias, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulations for this project:\n",
    "* XOR problem \n",
    "* Cart Pole Balancing\n",
    "* Mountain Car Climbing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR Problem (Very Basic NEAT Problem)\n",
    "\n",
    "| A | B | O |\n",
    "|---|---|---|\n",
    "| 0 | 0 | 0 |\n",
    "| 0 | 1 | 1 |\n",
    "| 1 | 0 | 1 |\n",
    "| 1 | 1 | 0 |\n",
    "\n",
    "#### Inputs and Outputs\n",
    "This the XOR problem, the inputs are simply `A` and `B` and output `O`. \n",
    "\n",
    "#### Fitness Function\n",
    "Since we know the labels for the XOR gate, we can make a fitness function `1 - sum_i((ei - ai)^2)`, ei meaning the expected and ai being the actual outputs. \n",
    "\n",
    "#### Hyperparameters \n",
    "This takes a lot of tweaking for any NEAT problem to optimize training, but the actual important ones are listed below\n",
    "* fitness_threshold = 3.9\n",
    "* pop_size = 150\n",
    "* feed_forward = True\n",
    "* species_fitness_func = max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to install all these modules correctly\n",
    "import sys \n",
    "import os\n",
    "import neat\n",
    "import gym\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-input XOR inputs and expected outputs.\n",
    "xor_inputs = [(0.0, 0.0), (0.0, 1.0), (1.0, 0.0), (1.0, 1.0)]\n",
    "xor_outputs = [   (0.0,),     (1.0,),     (1.0,),     (0.0,)]\n",
    "\n",
    "class Xor:\n",
    "    @staticmethod\n",
    "    def eval_genomes(genomes, config):\n",
    "        for genome_id, genome in genomes:\n",
    "            genome.fitness = 4.0\n",
    "            net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "            for xi, xo in zip(xor_inputs, xor_outputs):\n",
    "                output = net.activate(xi)\n",
    "                genome.fitness -= (output[0] - xo[0]) ** 2\n",
    "\n",
    "    @staticmethod\n",
    "    def run(config_file):\n",
    "        # Load configuration.\n",
    "        config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                            neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                            config_file)\n",
    "\n",
    "        # Create the population, which is the top-level object for a NEAT run.\n",
    "        p = neat.Population(config)\n",
    "\n",
    "        # Add a stdout reporter to show progress in the terminal.\n",
    "        p.add_reporter(neat.StdOutReporter(True))\n",
    "        # Redirect stdout to a txt file\n",
    "        actual_stdout = sys.stdout\n",
    "        sys.stdout = open('xor-output.txt', 'w')\n",
    "\n",
    "        # Run for up to 300 generations.\n",
    "        winner = p.run(Xor.eval_genomes, 300)\n",
    "\n",
    "        # Restore stdout \n",
    "        sys.stdout = actual_stdout\n",
    "\n",
    "        return winner, config\n",
    "\n",
    "    @staticmethod\n",
    "    def eval_winner(winner, config):\n",
    "        # Display the winning genome.\n",
    "        print('\\nBest genome:\\n{!s}'.format(winner))\n",
    "\n",
    "        # Show output of the most fit genome against training data.\n",
    "        print('\\nOutput:')\n",
    "        winner_net = neat.nn.FeedForwardNetwork.create(winner, config)\n",
    "        for xi, xo in zip(xor_inputs, xor_outputs):\n",
    "            output = winner_net.activate(xi)\n",
    "            print(\"input {!r}, expected output {!r}, got {!r}\".format(xi, xo, output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best genome:\n",
      "Key: 6912\n",
      "Fitness: 3.93413315555832\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=-2.5053889851167845, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t714 DefaultNodeGene(key=714, bias=-1.8540309741834953, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t1211 DefaultNodeGene(key=1211, bias=-1.127904750342468, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 714), weight=4.614806302099371, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-2, 1211), weight=-0.14491657968845467, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-1, 0), weight=0.3884322061108544, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-1, 714), weight=3.7211666625869557, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-1, 1211), weight=-0.760805411682394, enabled=True)\n",
      "\tDefaultConnectionGene(key=(714, 0), weight=-0.43187673076799654, enabled=False)\n",
      "\tDefaultConnectionGene(key=(714, 1211), weight=2.091788797171861, enabled=True)\n",
      "\tDefaultConnectionGene(key=(1211, 0), weight=3.7823247655120626, enabled=True)\n",
      "\n",
      "Output:\n",
      "input (0.0, 0.0), expected output (0.0,), got [3.879134082245461e-06]\n",
      "input (0.0, 1.0), expected output (1.0,), got [0.9977051705589961]\n",
      "input (1.0, 0.0), expected output (1.0,), got [0.7944866011223916]\n",
      "input (1.0, 1.0), expected output (0.0,), got [0.15370693239487337]\n"
     ]
    }
   ],
   "source": [
    "def run_xor():\n",
    "    # Determine path to configuration file. This path manipulation is\n",
    "    # here so that the script will run successfully regardless of the\n",
    "    # current working directory.\n",
    "    local_dir = os.path.abspath('')\n",
    "    config_path = os.path.join(local_dir, 'config-xor')\n",
    "    winner, config = Xor.run(config_path)\n",
    "    Xor.eval_winner(winner, config)\n",
    "    # Visualize the resulting neural network if possible\n",
    "    try:\n",
    "        import visualize\n",
    "        node_names = {-1:'A', -2: 'B', 0:'A XOR B'}\n",
    "        visualize.draw_net(config, winner, filename='xor-winner-genome', node_names=node_names)\n",
    "    except Exception:\n",
    "        pass\n",
    "run_xor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Neural Network\n",
    "If you downloaded Graphviz, you can visualize the result genome at `xor-winner-genome.svg`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cart Pole Balancing Problem\n",
    "We are utilizing the OpenAI Gym `CartPole-v1` environment for our next experiment. The system is controlled by applying a force of +1 or -1 to the cart. The pendulum starts upright, and the goal is to prevent it from falling over. A reward of +1 is provided for every timestep that the pole remains upright. The episode ends when the pole is more than 15 degrees from vertical, or the cart moves more than 2.4 units from the center. More about this environment can be explored at https://gym.openai.com/envs/CartPole-v1/\n",
    "\n",
    "#### Inputs and Outputs \n",
    "\n",
    "Inputs/observations are:\n",
    "* Cart Position\n",
    "* Cart Velocity\n",
    "* Pole Angle\n",
    "* Pole Angular Velocity\n",
    "\n",
    "Outputs/actions are:\n",
    "* Push cart to the left 0\n",
    "* Push cart to the right 1\n",
    "\n",
    "Fitness Function/Reward:\n",
    "* Number of steps/frames before termination\n",
    "\n",
    "Hyperparameters:\n",
    "* Again, this takes a lot of tweaking for any NEAT problem to optimize training\n",
    "* I tested activation of `clamped` or `sigmoid` and found that produces similar results\n",
    "* fitness of 200 because that is the goal set by OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check out the environment \n",
    "Let's take a look at the gym first with random inputs. We can run the next cell multiple things to see that randomly choosing actions will fail very quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score/fitness for this random sample run is 32.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "# Create the environment\n",
    "env = gym.make('CartPole-v1')\n",
    "# Initialize the environment\n",
    "observation = env.reset()\n",
    "# Loop until we reach termination\n",
    "done = False\n",
    "fitness = 0\n",
    "done = False\n",
    "while not done:\n",
    "    observation, reward, done, info = env.step(env.action_space.sample()) # take a random action\n",
    "    env.render()\n",
    "    fitness += reward\n",
    "env.close()\n",
    "print('The score/fitness for this random sample run is', fitness) # Frames/Steps this run last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cart Pole Balancing Code\n",
    "Now let's work on the training our agent with NEAT. Everything will be similar to the XOR problem which just a little difference: \n",
    "* We can utlize the `multiprocessing` library to use multiple CPUs and speed up training\n",
    "* we have another function eval_genome to evaulate individual genomes\n",
    "\n",
    "Because juypter notebook does not work with `multiprocessing`, so I have code for training in the file `train_pole_balancing.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: 314\n",
      "Fitness: 500.0\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=0.14381512908471206, response=1.0, activation=clamped, aggregation=sum)\n",
      "\t1 DefaultNodeGene(key=1, bias=-0.4701595934607206, response=1.0, activation=clamped, aggregation=sum)\n",
      "\t62 DefaultNodeGene(key=62, bias=-1.3185657977706486, response=1.0, activation=clamped, aggregation=sum)\n",
      "\t63 DefaultNodeGene(key=63, bias=-0.01867436303910147, response=1.0, activation=clamped, aggregation=sum)\n",
      "\t514 DefaultNodeGene(key=514, bias=1.4469735377372763, response=1.0, activation=clamped, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-4, 0), weight=-2.361693229075551, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-4, 62), weight=-0.2955341683285919, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-3, 1), weight=-0.8631475492114329, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-3, 63), weight=-1.958387045250396, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-3, 514), weight=0.8864010788492427, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-2, 62), weight=0.6628654429498149, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-2, 63), weight=-0.8288705598254769, enabled=True)\n",
      "\tDefaultConnectionGene(key=(62, 0), weight=-0.01974072575348637, enabled=True)\n",
      "\tDefaultConnectionGene(key=(62, 1), weight=-0.8086886806646181, enabled=True)\n",
      "\tDefaultConnectionGene(key=(63, 0), weight=1.761476161316391, enabled=True)\n",
      "\tDefaultConnectionGene(key=(63, 1), weight=-1.1938816395315421, enabled=True)\n",
      "\tDefaultConnectionGene(key=(514, 1), weight=-0.3061852182601346, enabled=True)\n"
     ]
    }
   ],
   "source": [
    "def pole_balancing():\n",
    "    from train_pole_balancing import PoleBalance\n",
    "    local_dir = os.path.abspath('')\n",
    "    config_path = os.path.join(local_dir, 'config-pole-balance')\n",
    "    winner, config = PoleBalance.run(config_path)\n",
    "    print(winner)\n",
    "\n",
    "    # Save the winner.\n",
    "    with open('winner-pole-balance', 'wb') as f:\n",
    "        pickle.dump(winner, f)\n",
    "\n",
    "    # Visualize the resulting neural network if possible\n",
    "    try:\n",
    "        import visualize\n",
    "        node_names = {-1: 'Cart Position', -2: 'Cart Velocity', \n",
    "        -3: 'Pole Angle', -4: 'Pole Angular Velocity', 0: 'Push cart to left', 1: 'Push cart to right'}\n",
    "        visualize.draw_net(config, winner, filename='pole-balancing-winner-genome', node_names=node_names)\n",
    "    except Exception:\n",
    "        pass\n",
    "pole_balancing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Neural Network\n",
    "If you downloaded Graphviz, you can visualize the result genome at `pole-balancing-winner-genome.svg`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the performance of our agent\n",
    "Let's use our winner stored with `pickle` to run the OpenAI gym environment again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score/fitness for this random sample run is 500.0\n"
     ]
    }
   ],
   "source": [
    "def test_pole_balancing():\n",
    "    # load the winner\n",
    "    with open('winner-pole-balance', 'rb') as f:\n",
    "        winner = pickle.load(f)\n",
    "\n",
    "\n",
    "    # Load the config file, which is assumed to live in\n",
    "    # the same directory as this script.\n",
    "    local_dir = os.path.abspath('')\n",
    "    config_path = os.path.join(local_dir, 'config-pole-balance')\n",
    "    config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                        neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                        config_path)\n",
    "\n",
    "    net = neat.nn.FeedForwardNetwork.create(winner, config)\n",
    "    env = gym.make('CartPole-v1')\n",
    "    observation = env.reset()\n",
    "    fitness = 0.0\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = np.argmax(net.activate(observation)) \n",
    "        observation, reward, done, info = env.step(action)\n",
    "        env.render()\n",
    "        fitness += reward\n",
    "    env.close()\n",
    "    print('The score/fitness for this random sample run is', fitness) # Frames/Steps this run last\n",
    "test_pole_balancing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mountain Car Problem\n",
    "A car is on a one-dimensional track, positioned between two \"mountains\". The goal is to drive up the mountain on the right; however, the car's engine is not strong enough to scale the mountain in a single pass. Therefore, the only way to succeed is to drive back and forth to build up momentum. More about this environment can be explored at https://gym.openai.com/envs/MountainCarContinuous-v0/\n",
    "\n",
    "#### Inputs and Outputs \n",
    "\n",
    "Inputs/observations are:\n",
    "* Cart Position\n",
    "* Cart Velocity\n",
    "\n",
    "Outputs/actions are:\n",
    "* Power Coefficient between -1 - 1\n",
    "\n",
    "Fitness Function/Reward:\n",
    "* Reward of 100 is awarded if the agent reached the flag (position = 0.45) on top of the mountain. Reward is decrease based on amount of energy consumed each step.\n",
    "\n",
    "Termination:\n",
    "    * The car position is more than 0.45\n",
    "    * Episode length is greater than 200\n",
    "\n",
    "Hyperparameters:\n",
    "* Again, this takes a lot of tweaking for any NEAT problem to optimize training\n",
    "* However, our activation must be `clamped` because we want an output between -1 and 1\n",
    "* Sigmoid will not work for this problem\n",
    "* fitness of 0 because the only time fitness is greater than 0 is when car reaches the flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check out the environment \n",
    "Let's take a look at the gym first with random inputs. We can run the next cell multiple things to see that randomly choosing actions will fail very quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "# Create the environment\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "# Initialize the environment\n",
    "observation = env.reset()\n",
    "# Loop until we reach termination\n",
    "done = False\n",
    "fitness = 0\n",
    "while not done:\n",
    "    observation, reward, done, info = env.step(env.action_space.sample()) # take a random action\n",
    "    env.render()\n",
    "    fitness += reward\n",
    "env.close()\n",
    "print('The score/fitness for this random sample run is', fitness) # Frames/Steps this run last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the previous problem, we train our problem with NEAT. This will take a lot more time than the pole balancing problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: 10584\n",
      "Fitness: 99.1209235786025\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=0.2808552807809455, response=1.0, activation=clamped, aggregation=sum)\n",
      "\t228 DefaultNodeGene(key=228, bias=0.1735738010381113, response=1.0, activation=clamped, aggregation=sum)\n",
      "\t2236 DefaultNodeGene(key=2236, bias=0.7021845169629942, response=1.0, activation=clamped, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 0), weight=5.980447707587803, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-2, 228), weight=-0.6500711894609923, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-2, 2236), weight=-0.3022207361846107, enabled=True)\n",
      "\tDefaultConnectionGene(key=(228, 2236), weight=-0.6273478660315946, enabled=True)\n",
      "\tDefaultConnectionGene(key=(2236, 0), weight=-0.4132314387970404, enabled=True)\n"
     ]
    }
   ],
   "source": [
    "def mountain_climbing():\n",
    "    from train_mountain_car import MountainCar\n",
    "    local_dir = os.path.abspath('')\n",
    "    config_path = os.path.join(local_dir, 'config-mountain-car')\n",
    "    winner, config = MountainCar.run(config_path)\n",
    "    print(winner)\n",
    "\n",
    "    # Save the winner.\n",
    "    with open('winner-mountain-car', 'wb') as f:\n",
    "        pickle.dump(winner, f)\n",
    "\n",
    "    # Visualize the resulting neural network if possible\n",
    "    try:\n",
    "        import visualize\n",
    "        node_names = {-1: 'Cart Position', -2: 'Cart Velocity', 0: 'Power Coefficient'}\n",
    "        visualize.draw_net(config, winner, filename='mountaincar-winner-genome', node_names=node_names)\n",
    "    except Exception:\n",
    "        pass\n",
    "mountain_climbing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Neural Network\n",
    "If you downloaded Graphviz, you can visualize the result genome at `pole-balancing-winner-genome.svg`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the performance of our agent\n",
    "Let's use our winner stored with `pickle` to run the OpenAI gym environment again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score/fitness for this random sample run is 98.97010562724965\n"
     ]
    }
   ],
   "source": [
    "def test_mountain_climbing():\n",
    "    # load the winner\n",
    "    with open('winner-mountain-car', 'rb') as f:\n",
    "        winner = pickle.load(f)\n",
    "\n",
    "\n",
    "    # Load the config file, which is assumed to live in\n",
    "    # the same directory as this script.\n",
    "    local_dir = os.path.abspath('')\n",
    "    config_path = os.path.join(local_dir, 'config-mountain-car')\n",
    "    config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                        neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                        config_path)\n",
    "\n",
    "    net = neat.nn.FeedForwardNetwork.create(winner, config)\n",
    "    env = gym.make('MountainCarContinuous-v0')\n",
    "    observation = env.reset()\n",
    "    fitness = 0.0\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = net.activate(observation)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        env.render()\n",
    "        fitness += reward\n",
    "    env.close()\n",
    "    print('The score/fitness for this random sample run is', fitness) # Frames/Steps this run last\n",
    "test_mountain_climbing()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5882122c6d093ec864ba68e1d4b88c57db0dcac0747db0685bc063533dae8454"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
